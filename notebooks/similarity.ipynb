{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import models\n",
    "import cv2\n",
    "from utils.utilities import *\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image,preprocess_image\n",
    "from pytorch_grad_cam.utils.model_targets import RawScoresOutputTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = get_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = groups.iloc[7:]\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(ResnetFeatureExtractor, self).__init__()\n",
    "        self.model = model\n",
    "        self.feature_extractor = torch.nn.Sequential(*list(self.model.children())[:-1])\n",
    "                \n",
    "    def __call__(self, x):\n",
    "        return self.feature_extractor(x)[:, :, 0, 0]\n",
    "    \n",
    "def load_img(path,resize_shape=None) -> np.ndarray:\n",
    "    img = cv2.imread(path)\n",
    "    if resize_shape == None:\n",
    "        return np.float32(img)/255\n",
    "    return np.float32(cv2.resize(img,resize_shape))/255\n",
    "    \n",
    "def img_to_tensor(img,device):\n",
    "    return preprocess_image(\n",
    "        img,\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "        ).to(device)\n",
    "\n",
    "def calculate_similarity(inspiration, final_image, model:ResnetFeatureExtractor, device):\n",
    "    inspiration_tensor = img_to_tensor(inspiration,device)\n",
    "    final_image_tensor = img_to_tensor(final_image,device)\n",
    "\n",
    "    features_inspiration = model(inspiration_tensor)[0,:]\n",
    "    features_final = model(final_image_tensor)[0,:]\n",
    "\n",
    "    return np.float32(torch.nn.functional.cosine_similarity(features_inspiration,features_final,dim=0).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet50(pretrained=True).to(device)\n",
    "resnet.eval()\n",
    "model = ResnetFeatureExtractor(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(final_data)):\n",
    "    print(f'Calculating cross-similarity for group {final_data.iloc[i].group_code}')\n",
    "    ai = final_data.iloc[i].ai_images\n",
    "    web = final_data.iloc[i].web_images\n",
    "    final = final_data.iloc[i].final_submissions\n",
    "    ai_aggregated_similarity, web_aggregated_similarity = 0, 0\n",
    "    max_similarity, picture1, picture2 = 0, \"\", \"\"\n",
    "\n",
    "    for ai_photo in ai:\n",
    "        im1 = load_img(ai_photo)\n",
    "        for final_photo in final:\n",
    "            im2 = load_img(final_photo)\n",
    "            similarity = calculate_similarity(im1, im2, model, device) # placebo for now\n",
    "            ai_aggregated_similarity += similarity\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                picture1, picture2 = im1, im2\n",
    "            \n",
    "    print(f'AI total similarity:\\t{ai_aggregated_similarity}')\n",
    "    \n",
    "    for web_photo in web:\n",
    "        im1 = load_img(web_photo)\n",
    "        for final_photo in final:\n",
    "            im2 = load_img(final_photo)\n",
    "            similarity = calculate_similarity(im1, im2, model, device) # placebo for now\n",
    "            web_aggregated_similarity += similarity\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                picture1, picture2 = im1, im2\n",
    "    \n",
    "    print(f'Web total similarity:\\t{web_aggregated_similarity}')\n",
    "\n",
    "    try:\n",
    "        print('Two most similar images are these:')\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(picture1)\n",
    "        plt.title(\"Inspiration\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(picture2)\n",
    "        plt.title(\"Submission\")\n",
    "        plt.show()\n",
    "    except Exception:\n",
    "        print('No images to compare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very primitive approach. Future ideas:\n",
    " - Use selective search or region proposal network across all images at the same time to extract the features from inspiration and final images\n",
    " - Create some ranking of highest similarity between images and display the most similar images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
